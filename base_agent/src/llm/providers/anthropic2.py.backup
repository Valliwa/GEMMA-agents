"""
Simple working Anthropic provider that routes to Gemma
Save as: base_agent/src/llm/providers/anthropic.py
"""

import logging
import requests
import json
import asyncio
from typing import Dict, Any, List, Optional, Union

logger = logging.getLogger(__name__)

class GemmaAnthropicProvider:
    """Simple Anthropic provider that routes to Gemma server"""
    
    def __init__(self, api_key: str = None, base_url: str = "http://localhost:8000"):
        self.api_key = api_key
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({'Content-Type': 'application/json'})
        logger.info(f"🔄 Anthropic provider initialized -> routing to Gemma at {base_url}")
    
    def _convert_messages_to_dict(self, messages: List[Any]) -> List[Dict]:
        """Convert Message objects to dictionaries"""
        converted = []
        for msg in messages:
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                # Extract text from content
                content_text = ""
                if hasattr(msg.content, '__iter__') and not isinstance(msg.content, str):
                    # Handle list of content blocks
                    for block in msg.content:
                        if hasattr(block, 'text'):
                            content_text += block.text + " "
                        else:
                            content_text += str(block) + " "
                else:
                    content_text = str(msg.content)
                
                converted.append({
                    "role": msg.role,
                    "content": content_text.strip()
                })
            elif isinstance(msg, dict):
                converted.append(msg)
            else:
                converted.append({"role": "user", "content": str(msg)})
        
        return converted
    
    async def create_completion(self, messages: List[Any], model: str = None, **kwargs) -> Any:
        """Create completion using Gemma server"""
        logger.info(f"🎯 Anthropic completion request intercepted -> Gemma")
        
        # Convert messages
        converted_messages = self._convert_messages_to_dict(messages)
        
        # Simple payload - no min() function to cause errors
        payload = {
            "model": "gemma-3-27b-it",
            "messages": converted_messages,
            "max_tokens": 256,  # Fixed value, no min() comparison
            "temperature": 0.7,
            "stream": False
        }
        
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.session.post(
                    f"{self.base_url}/v1/chat/completions",
                    json=payload,
                    timeout=300
                )
            )
            response.raise_for_status()
            result = response.json()
            
            # Extract text from OpenAI format
            if "choices" in result and len(result["choices"]) > 0:
                text_content = result["choices"][0]["message"]["content"]
                logger.info("✅ Successfully got response from Gemma")
                
                # Create response object with .content attribute
                class AnthropicResponse:
                    def __init__(self, text, provider_instance):
                        self.content = [AnthropicContentBlock(text)]
                        self.id = f"msg_{hash(str(converted_messages))}"
                        self.type = "message"
                        self.role = "assistant"
                        self.model = model or "gemma-3-27b-it"
                        self.stop_reason = "end_turn"
                        self.usage = provider_instance._create_compatible_usage(100, len(text.split()))
                    
                    def calculate_cost(self):
                        """Calculate cost - return 0 for local model"""
                        return 0.0
                
                class AnthropicContentBlock:
                    def __init__(self, text):
                        self.type = "text"
                        self.text = text
                
                return AnthropicResponse(text_content, self)
            else:
                raise Exception("No choices in response")
                
        except Exception as e:
            logger.error(f"❌ Gemma request failed: {e}")
            
            # Return error response
            class ErrorResponse:
                def __init__(self, error_msg, provider_instance):
                    self.content = [ErrorContentBlock(f"Error: {error_msg}")]
                    self.id = "error"
                    self.type = "error"
                    self.usage = provider_instance._create_compatible_usage(0, 0)
                
                def calculate_cost(self):
                    """Calculate cost - return 0 for local model"""
                    return 0.0
            
            class ErrorContentBlock:
                def __init__(self, text):
                    self.type = "text"
                    self.text = text
            
            return ErrorResponse(str(e), self)
    
    def _create_compatible_usage(self, input_tokens: int, output_tokens: int):
        """Create usage object compatible with the agent framework"""
        try:
            # Try to use the actual TokenUsage class from the framework
            from base_agent.src.types.llm_types import TokenUsage
            return TokenUsage(
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                total_tokens=input_tokens + output_tokens
            )
        except ImportError:
            # Fallback to a simple compatible object
            class CompatibleUsage:
                def __init__(self, input_tokens, output_tokens):
                    self.input_tokens = input_tokens
                    self.output_tokens = output_tokens
                    self.total_tokens = input_tokens + output_tokens
                
                def __add__(self, other):
                    # Make it compatible with += operations
                    if hasattr(other, 'input_tokens') and hasattr(other, 'output_tokens'):
                        return CompatibleUsage(
                            self.input_tokens + other.input_tokens,
                            self.output_tokens + other.output_tokens
                        )
                    return self
                
                def __radd__(self, other):
                    return self.__add__(other)
            
            return CompatibleUsage(input_tokens, output_tokens)
    
    async def create_continuation_completion(self, messages: List[Any], model: str = None, **kwargs) -> Any:
        """Create continuation completion"""
        logger.info(f"🔄 Continuation completion request intercepted -> Gemma")
        return await self.create_completion(messages, model, **kwargs)
    
    async def create_streaming_completion(self, messages: List[Any], model: str = None, **kwargs) -> Any:
        """Create streaming completion"""
        logger.info(f"🔄 Streaming completion request intercepted -> Gemma")
        return await self.create_completion(messages, model, **kwargs)
    
    async def messages(self, **kwargs):
        """Messages API compatibility"""
        messages = kwargs.get("messages", [])
        return await self.create_completion(messages, **kwargs)


# Client creation functions
def create_anthropic_client(api_key: str = None, **kwargs) -> GemmaAnthropicProvider:
    """Create Anthropic client that routes to Gemma"""
    logger.info("🔄 create_anthropic_client called -> Gemma")
    return GemmaAnthropicProvider(api_key=api_key, **kwargs)

def get_anthropic_client(api_key: str = None, **kwargs) -> GemmaAnthropicProvider:
    """Get Anthropic client that routes to Gemma"""
    logger.info("🔄 get_anthropic_client called -> Gemma")
    return GemmaAnthropicProvider(api_key=api_key, **kwargs)


class AnthropicProvider:
    """Main Anthropic provider class"""
    
    def __init__(self, api_key: str = None, **kwargs):
        self.client = GemmaAnthropicProvider(api_key=api_key, **kwargs)
        logger.info("🔄 AnthropicProvider initialized -> Gemma")
    
    async def create_completion(self, **kwargs):
        """Create completion"""
        return await self.client.create_completion(**kwargs)
    
    async def create_continuation_completion(self, **kwargs):
        """Create continuation completion"""
        logger.info("🔄 create_continuation_completion called -> Gemma")
        return await self.client.create_completion(**kwargs)
    
    async def create_streaming_completion(self, **kwargs):
        """Create streaming completion"""
        logger.info("🔄 create_streaming_completion called -> Gemma")
        return await self.client.create_completion(**kwargs)
    
    async def messages(self, **kwargs):
        """Messages API"""
        return await self.client.messages(**kwargs)


# For backward compatibility
async def anthropic_completion(**kwargs):
    """Completion function"""
    logger.info("🔄 anthropic_completion called -> Gemma")
    provider = GemmaAnthropicProvider()
    return await provider.create_completion(**kwargs)

async def create_streaming_completion(**kwargs):
    """Streaming completion function"""
    logger.info("🔄 create_streaming_completion called -> Gemma")
    provider = GemmaAnthropicProvider()
    return await provider.create_completion(**kwargs)

async def create_continuation_completion(**kwargs):
    """Continuation completion function"""
    logger.info("🔄 create_continuation_completion called -> Gemma")
    provider = GemmaAnthropicProvider()
    return await provider.create_completion(**kwargs)


# Main provider instance
provider = AnthropicProvider()

# Export all required functions
__all__ = [
    'create_anthropic_client',
    'get_anthropic_client', 
    'AnthropicProvider',
    'anthropic_completion',
    'create_streaming_completion',
    'create_continuation_completion',
    'provider'
]

logger.info("✅ Simple Anthropic provider module loaded -> All requests route to Gemma")
